encoder:
  vocab_size: 258
  embedding_dim: 128
  num_heads: 2
  num_layers: 1
  hash_len: 64
  d_ff: 64
  dropout: 0.1
  file_type_vocab: 935
  device: "mps"
decoder:
  vocab_size: 258
  embedding_dim: 128
  num_heads: 2
  num_layers: 1
  d_ff: 64
  dropout: 0.1
  chunk_size: 256
  device: "mps"
dataset:
  vocab_size: 258
  seq_len: 256
  path: "/Users/daniilogorodnikov/dataset/test"
train:
  num_epoch: 50
  interval4save: 200
  lr: 0.01
  device: "mps"
  precision: 32
  batch_size: 4
  num_workers: 0

