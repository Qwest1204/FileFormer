encoder:
  vocab_size: 258
  embedding_dim: 256
  num_heads: 8
  num_layers: 6
  hash_len: 32
  d_ff: 700
  dropout: 0.05
  file_type_vocab: 213
  device: "mps"
  attention_type: "MultiQueryAttention"
decoder:
  vocab_size: 258
  embedding_dim: 256
  num_heads: 8
  num_layers: 6
  d_ff: 700
  dropout: 0.05
  chunk_size: 2048
  device: "mps"
dataset:
  seq_len: 2048
  path: "/Users/daniilogorodnikov/dataset/test"
train:
  num_epoch: 50
  lr: 0.01
  device: "mps"
  batch_size: 2
  num_workers: 0

