{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import random\n",
    "from notus import FileDataset, ByteLevelTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from hashlib import sha256"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = FileDataset(\"/Users/daniilogorodnikov/dataset/test\", 512, 1)\n",
    "tokenizer = ByteLevelTokenizer()"
   ],
   "id": "d278e50b4980e19e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokens, masked_tokens, pads, hash, extention_tokenize = dataset.__getitem__(1)",
   "id": "7a0b8f3b78f0f08c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer.decode(tokens.tolist()[:50])",
   "id": "9c5221b3cc99e8c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer.decode(tokens.tolist())",
   "id": "ddb14ae53e8579b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, d in enumerate(loader):\n",
    "    if i % 200 == 0:\n",
    "        print(i)"
   ],
   "id": "b4ac8ea9a3614387",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": " x[4]",
   "id": "99c8144d51013a92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_file_name_by_byte(df, byte_value):\n",
    "    \"\"\"\n",
    "    Возвращает имя файла из датафрейма, если byte_value попадает в диапазон [start_byte, end_byte].\n",
    "\n",
    "    Параметры:\n",
    "    df -- pandas DataFrame с колонками file_name, start_byte, end_byte\n",
    "    byte_value -- значение для проверки (целое число)\n",
    "\n",
    "    Возвращает:\n",
    "    str -- имя файла, если byte_value в диапазоне, иначе None\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        if row['start_byte'] <= byte_value <= row['end_byte']:\n",
    "            return row['file_name'], row['start_byte'], row['end_byte']\n",
    "    return None"
   ],
   "id": "51ed3799da851301",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x = get_file_name_by_byte(dataset.table_init_data, 453)",
   "id": "104a3163d05658bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x[1]",
   "id": "c0a35990447d08d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "88c8d0ccb3fbf32d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from notus import ByteLevelTokenizer",
   "id": "8b012e771da5a1ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer = ByteLevelTokenizer()",
   "id": "1a12329aeaebb96e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_tokens = []",
   "id": "447af88ee7a9c023",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from random import randint",
   "id": "14efb57c90aaef45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_data(file, batch_size, seq_len):\n",
    "    part_of_file = randint(0, (file.stat().st_size)//seq_len)\n",
    "    out_tokens = []\n",
    "    with open(file, 'rb') as f:\n",
    "        f.seek(part_of_file)\n",
    "        for _ in range(batch_size):\n",
    "            byte_chunk = f.read(seq_len)\n",
    "            hex_chunk = byte_chunk.hex()\n",
    "            tokens = tokenizer.encode(hex_chunk)\n",
    "            if len(tokens) < 512:\n",
    "                tokens.extend([0]*(512 - len(tokens)))\n",
    "            out_tokens.append(tokens)\n",
    "    f.close()\n",
    "    return out_tokens\n"
   ],
   "id": "1041987b3f4684b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = get_data(files[3], 3, 512)",
   "id": "7e0e9e4202c7aaae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer.decode(data[0])",
   "id": "75f85916259f081a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer.decode(data[1])",
   "id": "729156c1b59a8294",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(files[3], 'rb') as f:\n",
    "\n",
    "        byte_chunk = f.read(512)\n",
    "        if not byte_chunk:\n",
    "            break\n",
    "        hex_chunk = byte_chunk.hex()\n",
    "        tokens = tokenizer.encode(hex_chunk)\n",
    "        if len(tokens) < 512:\n",
    "            tokens.extend([0]*(512 - len(tokens)))\n",
    "        all_tokens.append(tokens)"
   ],
   "id": "cbe96654b7aa3c45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(all_tokens)",
   "id": "b362ab5ffaa5d7c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(all_tokens[217])",
   "id": "77ae7fa2621e9d8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_tokens[217]",
   "id": "423a8b7d74f95b95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer.decode(all_tokens[217])",
   "id": "ac75ffa3b5b6c6fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "111441//512",
   "id": "33cf774fc38382c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer.vocab_size",
   "id": "ac56ba6cac3e7983",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6da1e58018942ea8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
