{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:17:56.052884Z",
     "start_time": "2025-05-25T21:17:56.040376Z"
    }
   },
   "source": [
    "import os.path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from tokenizer import Tokenizer\n",
    "from file_dataset import FileDataset\n",
    "from transformer_model import build_transformer"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:17:56.448004Z",
     "start_time": "2025-05-25T21:17:56.444025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import SyncConfig\n",
    "import tempfile\n",
    "import ray.train.torch"
   ],
   "id": "b06461ec9eebd1fb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:17:56.826806Z",
     "start_time": "2025-05-25T21:17:56.821255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_fn(dataset):\n",
    "    tokenizer = Tokenizer()\n",
    "    VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    trainloader = ray.train.torch.prepare_data_loader(dataloader)\n",
    "    print(\"all OK\")\n",
    "    transformer = build_transformer(vocab_size=VOCAB_SIZE,\n",
    "                                d_model=512,\n",
    "                                max_seq_len=128,\n",
    "                                d_ff=1024,\n",
    "                                dropout=0.1,\n",
    "                                n_layers=6,\n",
    "                                n_heads=8,\n",
    "                                factor=2)\n",
    "    print(\"all OK\")\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=5)\n",
    "    optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "\n",
    "    model = ray.train.torch.prepare_model(transformer)\n",
    "    print(\"all OK\")\n",
    "    for epoch in range(10):\n",
    "        if ray.train.get_context().get_world_size() > 1:\n",
    "            trainloader.sampler.set_epoch(epoch)\n",
    "        for batch in trainloader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            # Расчет потерь (сравниваем выход с входом)\n",
    "            loss = criterion(outputs.view(-1, outputs.shape[-1]), input_ids.view(-1))\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        metrics = {\"loss\": loss.item(), \"epoch\": epoch}\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(tmpdir, \"model.pt\")\n",
    "                       )\n",
    "            ray.train.report(metrics,\n",
    "                             checkpoint=ray.train.Checkpoint.from_directory(tmpdir),\n",
    "                             )\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "            print(metrics)\n"
   ],
   "id": "2abf6036023bc1b7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:18:22.233117Z",
     "start_time": "2025-05-25T21:17:57.245967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaling_config = ray.train.ScalingConfig(num_workers=1, use_gpu=False)\n",
    "dataset = torch.load(\"dataset.pt\", weights_only=False)\n",
    "# [5] Launch distributed training job.\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_fn,\n",
    "    scaling_config=scaling_config,\n",
    "    train_loop_config=dataset\n",
    "    # [5a] If running in a multi-node cluster, this is where you\n",
    "    # should configure the run's persistent storage that is accessible\n",
    "    # across all worker nodes.\n",
    "    # run_config=ray.train.RunConfig(storage_path=\"s3://...\"),\n",
    ")"
   ],
   "id": "18e7fd8f292b5e10",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-05-25T21:28:34.417784Z",
     "start_time": "2025-05-25T21:18:22.253254Z"
    }
   },
   "cell_type": "code",
   "source": "result = trainer.fit()",
   "id": "60ff32de1a5cabcf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 00:20:35,032\tINFO worker.py:1879 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "2025-05-26 00:21:20,486\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `<FrameworkTrainer>(...)`.\n",
      "2025-05-26 00:21:20,491\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-05-26 00:26:11 (running for 00:04:25.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-05-26_00-20-32_790466_2079/artifacts/2025-05-26_00-21-46/TorchTrainer_2025-05-26_00-18-41/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:00:23.728795Z",
     "start_time": "2025-05-25T19:59:46.394546Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = FileDataset(\"/Users/daniilogorodnikov/dataset/app\", 'sha256', 128)",
   "id": "6d04c3136193a73c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 671/671 [00:36<00:00, 18.62it/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:01:00.633784Z",
     "start_time": "2025-05-25T20:00:23.738823Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(dataset, \"dataset.pt\")",
   "id": "6c60c911f60ea81c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:48:57.002866Z",
     "start_time": "2025-05-25T20:48:42.069310Z"
    }
   },
   "cell_type": "code",
   "source": "torch.load(\"dataset.pt\", weights_only=False)",
   "id": "e4c49ab15153f75a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1050452b0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daniilogorodnikov/PycharmProjects/Notus/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:51:11.451699Z",
     "start_time": "2025-05-25T20:51:11.449184Z"
    }
   },
   "cell_type": "code",
   "source": "os.path.join(\"tmp/\", \"dataset.pt\")",
   "id": "6116668e16a91853",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp/dataset.pt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ed03b68661343e17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
