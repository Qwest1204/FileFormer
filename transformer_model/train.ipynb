{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T11:58:53.510210Z",
     "start_time": "2025-05-25T11:58:52.836987Z"
    }
   },
   "source": [
    "import os.path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from tokenizer import Tokenizer\n",
    "from file_dataset import FileDataset\n",
    "from transformer_model import build_transformer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T11:58:54.289828Z",
     "start_time": "2025-05-25T11:58:53.513387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import SyncConfig\n",
    "import tempfile\n",
    "import ray.train.torch"
   ],
   "id": "b06461ec9eebd1fb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T11:58:54.297867Z",
     "start_time": "2025-05-25T11:58:54.293908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_fn(tmpdir):\n",
    "    tokenizer = Tokenizer()\n",
    "    VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "    dataset = FileDataset(\"/Users/daniilogorodnikov/dataset/app\", 'sha256', 128)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    trainloader = ray.train.torch.prepare_data_loader(dataloader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=5)\n",
    "    optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "\n",
    "    transformer = build_transformer(vocab_size=VOCAB_SIZE,\n",
    "                                d_model=512,\n",
    "                                max_seq_len=128,\n",
    "                                d_ff=1024,\n",
    "                                dropout=0.1,\n",
    "                                n_layers=6,\n",
    "                                n_heads=8,\n",
    "                                factor=2)\n",
    "\n",
    "    model = ray.train.torch.prepare_model(transformer)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        if ray.train.get_context().get_world_size() > 1:\n",
    "            trainloader.sampler.set_epoch(epoch)\n",
    "        for batch in trainloader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            # Расчет потерь (сравниваем выход с входом)\n",
    "            loss = criterion(outputs.view(-1, outputs.shape[-1]), input_ids.view(-1))\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        metrics = {\"loss\": loss.item(), \"epoch\": epoch}\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(tmpdir, \"model.pt\")\n",
    "                       )\n",
    "            ray.train.report(metrics,\n",
    "                             checkpoint=ray.train.Checkpoint.from_directory(tmpdir),\n",
    "                             )\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "            print(metrics)\n"
   ],
   "id": "2abf6036023bc1b7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T11:58:57.696785Z",
     "start_time": "2025-05-25T11:58:57.572101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaling_config = ray.train.ScalingConfig(num_workers=2, use_gpu=False)\n",
    "\n",
    "# [5] Launch distributed training job.\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_fn,\n",
    "    scaling_config=scaling_config,\n",
    "    # [5a] If running in a multi-node cluster, this is where you\n",
    "    # should configure the run's persistent storage that is accessible\n",
    "    # across all worker nodes.\n",
    "    # run_config=ray.train.RunConfig(storage_path=\"s3://...\"),\n",
    ")"
   ],
   "id": "18e7fd8f292b5e10",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T11:59:27.249336Z",
     "start_time": "2025-05-25T11:59:06.300550Z"
    }
   },
   "cell_type": "code",
   "source": "result = trainer.fit()",
   "id": "60ff32de1a5cabcf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 14:59:08,975\tINFO worker.py:1888 -- Started a local Ray instance.\n",
      "2025-05-25 14:59:09,595\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `<FrameworkTrainer>(...)`.\n",
      "2025-05-25 14:59:09,597\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-05-25 14:59:09 (running for 00:00:00.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-05-25_14-59-06_331250_54916/artifacts/2025-05-25_14-59-09/TorchTrainer_2025-05-25_14-59-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(TorchTrainer pid=54954)\u001B[0m Started distributed worker processes: \n",
      "\u001B[36m(TorchTrainer pid=54954)\u001B[0m - (node_id=fce7f84855974765396ce14e761d727c7ff489cd5a60b2a887f44415, ip=127.0.0.1, pid=54959) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001B[36m(TorchTrainer pid=54954)\u001B[0m - (node_id=fce7f84855974765396ce14e761d727c7ff489cd5a60b2a887f44415, ip=127.0.0.1, pid=54958) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001B[36m(RayTrainWorker pid=54959)\u001B[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "  0%|          | 0/780 [00:00<?, ?it/s]\n",
      "  1%|          | 4/780 [00:00<00:45, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-05-25 14:59:14 (running for 00:00:05.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-05-25_14-59-06_331250_54916/artifacts/2025-05-25_14-59-09/TorchTrainer_2025-05-25_14-59-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/780 [00:00<?, ?it/s]\n",
      " 14%|█▍        | 110/780 [00:05<00:21, 31.40it/s]\u001B[32m [repeated 48x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-05-25 14:59:19 (running for 00:00:10.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-05-25_14-59-06_331250_54916/artifacts/2025-05-25_14-59-09/TorchTrainer_2025-05-25_14-59-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 204/780 [00:10<00:50, 11.32it/s]\u001B[32m [repeated 42x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-05-25 14:59:24 (running for 00:00:15.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-05-25_14-59-06_331250_54916/artifacts/2025-05-25_14-59-09/TorchTrainer_2025-05-25_14-59-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 249/780 [00:12<00:37, 14.16it/s]\n",
      "2025-05-25 14:59:26,967\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-05-25 14:59:26,971\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/daniilogorodnikov/ray_results/TorchTrainer_2025-05-25_14-59-06' in 0.0028s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-05-25 14:59:26 (running for 00:00:17.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-05-25_14-59-06_331250_54916/artifacts/2025-05-25_14-59-09/TorchTrainer_2025-05-25_14-59-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 14:59:27,239\tINFO tune.py:1041 -- Total run time: 17.64 seconds (17.33 seconds for the tuning loop).\n",
      "2025-05-25 14:59:27,240\tWARNING tune.py:1051 -- Training has been interrupted, but the most recent state was saved.\n",
      "Resume training with: <FrameworkTrainer>.restore(path=\"/Users/daniilogorodnikov/ray_results/TorchTrainer_2025-05-25_14-59-06\", ...)\n",
      "\u001B[36m(RayTrainWorker pid=54959)\u001B[0m /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/resource_tracker.py:276: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown: {'/mp-ddnq7gzl'}\n",
      "\u001B[36m(RayTrainWorker pid=54959)\u001B[0m   warnings.warn(\n",
      "\u001B[36m(RayTrainWorker pid=54958)\u001B[0m /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/resource_tracker.py:276: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown: {'/mp-qqdixulz'}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d04c3136193a73c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
